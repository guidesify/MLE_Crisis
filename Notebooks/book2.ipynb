{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -U sagemaker\n",
    "!pip install scikit-learn==1.2.1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Bucket"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bucket Name Generator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import random\n",
    "\n",
    "def bucket_generator():\n",
    "\n",
    "    str = ''.join(random.choice(string.ascii_uppercase + string.digits) for i in range(6))\n",
    "    rand_bucket = 'MLE_Crisis'+str\n",
    "    return rand_bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Create an S3 client\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "# Specify a unique bucket name\n",
    "bucket_name = bucket_generator()\n",
    "prefix = \"model\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create S3 Bucket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the S3 bucket\n",
    "try:\n",
    "    # Create the S3 bucket\n",
    "    s3_client.create_bucket(Bucket=bucket_name)\n",
    "    print(\"Bucket created successfully!\")\n",
    "except ClientError as e:\n",
    "    # Check if the error is due to bucket already existing\n",
    "    error_code = e.response['Error']['Code']\n",
    "    if error_code == 'BucketAlreadyOwnedByYou':\n",
    "        print(\"Bucket already exists. Continuing with the existing bucket.\")\n",
    "    else:\n",
    "        print(\"An error occurred while creating the bucket:\", error_code)\n",
    "        raise"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the local file as a DataFrame using pandas\n",
    "# Specify the local file path and desired S3 object key\n",
    "local_file_path = 'data.csv'\n",
    "df = pd.read_csv(local_file_path)\n",
    "df = df[['target','text']]\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload to S3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sagemaker session to upload data to S3\n",
    "import sagemaker\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "# batch_1, batch_2 = train_test_split(df, test_size=0.2, random_state=2023)\n",
    "\n",
    "# Save the train and test datasets to local files\n",
    "# batch_1.to_csv('batch_1.csv', index=False)\n",
    "# batch_2.to_csv('batch_2.csv', index=False)\n",
    "batch_1_input_path = sagemaker_session.upload_data(\"batch_1.csv\", bucket_name, os.path.join('batch_1'))\n",
    "batch_2_input_path = sagemaker_session.upload_data(\"batch_2.csv\", bucket_name, os.path.join('batch_2'))\n",
    "\n",
    "print(batch_1_input_path)\n",
    "print(batch_2_input_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the current execution role for training. It needs access to S3\n",
    "role = sagemaker.get_execution_role()\n",
    "print(role)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Model Training Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn import SKLearn\n",
    "\n",
    "def train_model(train_script, dependencies_script, batch_path):\n",
    "    # Set up the SKLearn estimator with dependencies\n",
    "    sk_estimator = SKLearn(\n",
    "        entry_point=train_script,\n",
    "        dependencies=dependencies_script,\n",
    "        role=role,\n",
    "        instance_count=1,\n",
    "        instance_type=\"ml.c5.xlarge\",\n",
    "        framework_version=\"1.2-1\",\n",
    "        script_mode=True,\n",
    "        py_version='py3',\n",
    "        sagemaker_session=sagemaker_session,\n",
    "        output_path=\"s3://{}/{}\".format(bucket_name, prefix),\n",
    "        base_job_name= \"sagemaker-crisis-detection\",\n",
    "        code_location= \"s3://{}/{}\".format(bucket_name, \"jobs\")\n",
    "    \n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    print(batch_path)\n",
    "    s3_input = TrainingInput(batch_path)\n",
    "    sk_estimator.fit({'train': s3_input}, wait=False)\n",
    "\n",
    "    return sk_estimator\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base Model Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_estimator = train_model('train.py', ['utils.py'], batch_1_input_path)\n",
    "\n",
    "model_data = base_estimator.model_data\n",
    "image_uri = base_estimator.image_uri\n",
    "model_role = base_estimator.role\n",
    "\n",
    "print(f\"Model Data: {model_data}\\nImage URI: {image_uri}\\nModel Role: {model_role}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import tarfile\n",
    "\n",
    "def load_model(bucket_dir, model_ver):\n",
    "    s3_client.download_file(bucket_dir, model_ver.split('s3://{}/'.format(bucket_dir))[1], 'model.tar.gz')\n",
    "    # Extract the model file from the tar.gz archive\n",
    "    with tarfile.open('model.tar.gz', 'r:gz') as tar:\n",
    "        tar.extractall('.')\n",
    "        \n",
    "    # Load the trained model\n",
    "    model = joblib.load('model.joblib')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_model = load_model(bucket_name)\n",
    "print(curr_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_model.named_steps['clf'].partial_fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incremental Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incremental_estimator = train_model('incremental.py', ['utils.py'], batch_2_input_path)\n",
    "\n",
    "new_model_data = incremental_estimator.model_data\n",
    "new_image_uri = incremental_estimator.image_uri\n",
    "new_model_role = incremental_estimator.role\n",
    "\n",
    "print(f\"Model Data: {new_model_data}\\nImage URI: {new_image_uri}\\nModel Role: {new_model_role}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploy Serverless Endpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.serverless import ServerlessInferenceConfig\n",
    "\n",
    "# Create an empty ServerlessInferenceConfig object to use default values\n",
    "serverless_config = ServerlessInferenceConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify MemorySizeInMB and MaxConcurrency in the serverless config object\n",
    "serverless_config = ServerlessInferenceConfig(\n",
    "  memory_size_in_mb=1024,\n",
    "  max_concurrency=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = base_estimator\n",
    "\n",
    "sk_predictor = serverless_estimator.deploy(serverless_inference_config=serverless_config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check list of endpoints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Boto3 SageMaker client\n",
    "sagemaker_client = boto3.client('sagemaker')\n",
    "\n",
    "# List the endpoints\n",
    "response = sagemaker_client.list_endpoints()\n",
    "\n",
    "# Iterate through the endpoints and print their names\n",
    "for endpoint in response['Endpoints']:\n",
    "    print(endpoint['EndpointName'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# client = sagemaker_session.sagemaker_runtime_client\n",
    "\n",
    "# # Define the input data in the desired format\n",
    "# input_data = {\"Input\": [\"This is a disaster\",\"Hello world\"]}\n",
    "\n",
    "# # Convert the input data to JSON payload\n",
    "# payload = json.dumps(input_data)\n",
    "\n",
    "# # Invoke the endpoint to get the prediction\n",
    "# response = client.invoke_endpoint(\n",
    "#     EndpointName='sagemaker-crisis-detection-2023-06-04-05-43-17-303',\n",
    "#     ContentType='application/json',\n",
    "#     Body=payload\n",
    "# )\n",
    "\n",
    "# # Parse the prediction response\n",
    "# response_body = response['Body'].read().decode('utf-8')\n",
    "# prediction_result = json.loads(response_body)['Output']\n",
    "# print(response_body)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Endpoint Cleanup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for endpoint in response['Endpoints']:\n",
    "    endpoint_name = endpoint['EndpointName']\n",
    "    sagemaker_client.delete_endpoint(EndpointName=endpoint_name)\n",
    "    print(f\"Deleted endpoint: {endpoint_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response['Endpoints']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = 'sagemaker-crisis-detection-2023-06-04-05-43-17-303' # Replace with your endpoint name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def call_model(data):\n",
    "    client = sagemaker_session.sagemaker_runtime_client\n",
    "\n",
    "    payload = json.dumps(data)\n",
    "\n",
    "    response = client.invoke_endpoint(\n",
    "        EndpointName=endpoint_name\n",
    "        ContentType='application/json',\n",
    "        Body=payload\n",
    "    )\n",
    "\n",
    "    response_body = response['Body'].read().decode('utf-8')\n",
    "    prediction_result = json.loads(response_body)['Output']\n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
